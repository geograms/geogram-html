
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Whisper WebM Transcriber</title>
  <style>
    body { background: #111; color: #eee; font-family: monospace; padding: 20px; }
    textarea { width: 100%; height: 300px; background: #000; color: #0f0; font-size: 14px; margin-top: 10px; }
  </style>
</head>
<body>
  <h2>Select a .webm audio file to transcribe:</h2>
  <input type="file" id="audioInput" accept=".webm">
  <textarea id="output" readonly>Loading model from ggml.ggerganov.com ...</textarea>

  <script>
    window.Module = window.Module || {};
    const output = document.getElementById("output");

    Module.print = (text) => { output.value += text + "\n"; output.scrollTop = output.scrollHeight; };
    Module.printErr = (text) => { output.value += "ERR: " + text + "\n"; };
    Module.setStatus = (text) => { output.value += "STATUS: " + text + "\n"; };

    let whisperInstance = null;

    async function loadModel() {
      const res = await fetch("https://geogram.info/lib/voice/ggml-small-q5_1.bin");
      const buf = await res.arrayBuffer();
      Module.FS_createDataFile("/", "whisper.bin", new Uint8Array(buf), true, true);
      whisperInstance = Module.init("whisper.bin");
      output.value = "Model loaded. Select a .webm file to transcribe.\n";
    }

    function resampleToMono16kHz(audioBuffer) {
      const offlineCtx = new OfflineAudioContext(1, 16000 * audioBuffer.duration, 16000);
      const source = offlineCtx.createBufferSource();
      const mono = offlineCtx.createBuffer(1, audioBuffer.length, audioBuffer.sampleRate);

      const mix = audioBuffer.numberOfChannels > 1
        ? audioBuffer.getChannelData(0).map((v, i) =>
            0.5 * (v + audioBuffer.getChannelData(1)[i]))
        : audioBuffer.getChannelData(0);

      mono.copyToChannel(new Float32Array(mix), 0);
      source.buffer = mono;
      source.connect(offlineCtx.destination);
      source.start();
      return offlineCtx.startRendering();
    }

    async function handleFile(file) {
      output.value = "Reading file...\n";
      const reader = new FileReader();
      reader.onload = async () => {
        const audioCtx = new AudioContext();
        try {
          const decoded = await audioCtx.decodeAudioData(reader.result);
          const resampled = await resampleToMono16kHz(decoded);
          const pcm = resampled.getChannelData(0);
          output.value = "Transcribing...\n";
          setTimeout(() => {
            const result = Module.full_default(whisperInstance, pcm, "en", 8, false);
            output.value += "\nDone.\n";
          }, 100);
        } catch (e) {
          output.value = "Decoding error: " + e;
        }
      };
      reader.readAsArrayBuffer(file);
    }

    document.getElementById("audioInput").addEventListener("change", (e) => {
      if (e.target.files.length > 0 && whisperInstance) {
        handleFile(e.target.files[0]);
      }
    });
  </script>

  <script src="whisperlib.js"></script>
  <script>loadModel();</script>
</body>
</html>
